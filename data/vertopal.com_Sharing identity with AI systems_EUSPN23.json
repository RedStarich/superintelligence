{"\ufeff\n\nAvailable online at\n\n\nScienceDirect\n\n\nProcedia Computer Science 00 (2023) 000\u2013000\n\nwww.elsevier.com/locate/procedia \nThe 14th International Conference on Emerging Ubiquitous Systems and Pervasive Networks \t\t(EUSPN 2023) \n\tNovember 1-3, 2023, Almaty, Kazakhstan \nSharing Identity with AI Systems: \nA Comprehensive Review \nAlina Gutorevaa*\na Information Technology and Engineering, Kazakh-British Technical University, Almaty, Kazakhstan \nAbstract \nSystems, including humans and artificial agents, are involved in a set of coordinated tasks. The technology becomes intertwined with an individual\u2019s identity in daily activity. The concept explored here encapsulates the extended-self idea within social identity theory. In this comprehensive review, the idea of shared identity of individuals connecting with AI systems is explored, along with methods, applications, and implications. Assuming that the transition to AI-enhanced society happens ubiquitously, in different categories (e.g., programming, text comprehension), realizing shared identity with AI systems is an important step in societal development. Because identity consists of personal and social experience, the social experience is reflected in global environment, and it in turn extends to the artificial environment. In such layered identity, AI systems act as part of an individual's extended identity, allowing them to navigate digital spaces, share personal information, and interact with various services. The main advantage of shared identity with AI systems is in coordination improvement and task efficiency: people are better at managing tasks when a common identity is highlighted": null, " the same might be assumed for the interaction of a human and AI systems. The application of such ideas is discussed within personal, social and global identities including a new social norm, personification, bias identification, recommender system, social network, ethical considerations, cybersecurity, medical use, and developing a sense of global identity and propose ideas for refining AI Global policy. The implication for work, ethics and medical use is explored. \n\u00a9 2023 The Authors. Published by Elsevier B.V. \nThis is an open access article under the CC BY-NC-ND license Peer-review under the responsibility of the Conference Program C\n* Corresponding author. Tel.: +7 701 958 40 91. \n\tE-mail address: a.gutoreva@kbtu.kz \n1877-0509 \u00a9 2023 The Authors. Published by Elsevier B.V. \nThis is an open access article under the CC BY-NC-ND license Peer-review under responsibility of the Conference Program Ch\n\n2 \tAlina Gutoreva / Procedia Computer Science 00 (2023) 000\u2013000\nKeywords: AI systems, shared identity, self-aspect, global policy \n1.Introduction \nGilbert and Malone (1995) poetically put, \u201cthe human skin [is seen] as a special boundary that separates one set of \u2018causal forces\u2019 from another. On the sunny side of the epidermis are the external or situational forces that press inward on the person, and on the meaty side are the internal or personal forces that exert pressure outward\u201d. \nHumans are biological creatures, we share common ancestors with chimpanzees tracing our genes back to a fruitfly, and algae. Yet, most of our contemporary daily activities are interlinked with technology, including artificial intelligence (AI) systems\u2020. If individuals are becoming more interconnected, should we incorporate he ways that contribute to this connectedness \u2013 language, mobile phones, algorithms \u2013 to become part of our identity? If so, does AI aiming to advance all of humanity must be shared amongst all, just as genes do, in order to be accepted within its humanitarian goal? What about sharing values with artificial systems, such as efficiency and unambiguity? What is our common \u2018skin\u2019 with AI? These are important questions to ponder, but as humanity is underway of becoming intimately connected, with the ability to share and receive any information in almost infinite quantity and in various qualities, these questions need to be addressed. Indeed, sharing identity with AI systems is becoming part of our individual and social identities, which can be viewed and discussed in terms of global environment that under global policy [1], [2]. In this review article, we explore what it means to be sharing identity with AI systems. \n Table 1. Policy for Shared Identity with AI systems \nIdentity\nPrinciple\nExplanation\nRange\nof\nExample\nShared\nWeight in AI\n\n\n\nchange\n\nIdentity\nsystems\nGlobal\nExpertise\nThe skillset or talent\nStable\nPhD in\nAugmented\n3\n\n\nthat an individual\n(specificity)\nComputer\nskill\n\n\n\nholds and would like\nDynamic\nScience\n\n\nSocial\nSocial norm\nto develop.\n\n\n\n2\n\n\n\n(growth)\n\nImproved\n\n\n\n\n\nPunctuality\n\n\n\n\nCollection of rules\nStable\n\n\n\n\n\nand patterns, cultural\n(traditions)\n\ncoordination\n\n\n\nhabits that unite\nDynamic\n\nand\n\nPersonal\nIndividuality\nindividuals": null, " manners\n\nBook\nunderstanding\n1\n\n\n\n(fashion)\n\n\n\n\n\nand politeness.\n\n\n\n\n\n\n\nStable\n\nUniqueness": null, "\n\n\n\nLinked to expertise,\n\n\n\n\n\n\nbut directed to\n(memory)\ngenre\nhow you are\n\n\n\nsatisfying self rather\nDynamic\npreference\ndistinguished\n\n\n\nthan contributing to\n\n\nfrom others\n\n\n\n\n(reflection)\n\n\n\n\n\nsocial good. Society\n\n\n\n\n\n\nworks to contribute to\n\n\n\n\n\n\nsustain diversity.\n\n\n\n\nSharing identity with AI systems is about the necessity to understand intricate problems humanity faces, one of which is resolving conflict within Global Governance whilst developing expertise. Identity is a two-way process \u2013 it is malleable and dynamic. In cognitive and psychological sciences, self-concept is a part of social identity, which, in turn, describes the idea that individuals with unique personal attributes necessarily share some common traits with others. that define their common social identity [3], [4]. Social identity is also known as social categorization because individuals place themselves into categories when associating with others, i.e., individuals tend to self-stereotype according to the chosen category. Social comparison characterizes the similarity between individuals and describes how people affiliate with others highlighting similar traits. This, in turn, is the base for social communication, \n\u2020The choice to use technology and engage in its complexity is based on availability and preference. \n\nAuthor name / Procedia Computer Science 00 (2023) 000\u2013000 \t3\ninteraction and coordination to receive or provide support and feel belonging to a community. These are paramount to social connection, and because being social is inevitable for individual wellbeing. \nAs people change from being psychologically separate individuals, even though physically gathered together, to sharing a common social identity, so changes behaviour. People start attending to each other, talking to each other [5]. According to the theories in social view identity is in terms of a separate individual connected to society within a global environment encapsulating various organisms, which would encapsulate the ability to experience natural and virtual realities. In this article, the idea of different layers of identity extending to AI systems is explored, along with the methods of such connection, its applications, and implications. Three main levels are discussed: individual or personal level of identity, social identity, and global identity \u2013 all which are extended by AI systems (Table 1). \n2.Methods \n Sharing identity with AI systems can be viewed within and extended-self idea. An extended self, like an artificial prosthesis enhances and augments a person's physical capabilities, AI systems enhance a person's interaction with the digital world and manage identity-related information [6], [7].Sharing identity with AI systems is established through several methods, which can be synchronous, asynchronous or mixed (Fig. 1a). \na\na\nb\nFig. 1 a. Synchronous and Asynchronous methods of shared identity with AI systems. \nb. Different layers of shared identities include AI systems, which is versatile and expanding layer. \n\t\t2.1 Synchronous \n\t Synchronous methods of sharing identity with AI systems involve tasks that require real-time user input and interaction. In synchronous methods, such as playing a video character or using an avatar, the user of shared identity experiences the digital environment by sharing AI identity and manipulating the digital environment through it. The idea of shared identity with a synced artificial system is not new and is a well-established feature in video game industry, which is the fastest-growing entertainment industry [8]. In a video game, one takes a game character with specific attributes and acts with it, as if it was self in a separate environment. The distinction between a game character and self is clearly realized \u2013 the character acts as the prosthesis of an individual in virtual reality. The use of an avatar is another example of such a synchronous method, in which a user personalises a character to represent self in digital environment. Additionally, since social media uses various AI systems, one can argue that this is one of the most prominent ways of sharing identity. In the same sense, AI systems, such as health monitoring, even though do not act as a character, but can be perceived as a digital prosthesis, an extended self, in an artificial environment to accompany an individual\u2019s daily digital activities [9], [10]. Cognitive prostheses themselves can be also viewed as synchronous \n\n4 \tAlina Gutoreva / Procedia Computer Science 00 (2023) 000\u2013000\nidentity sharing as they require user input to, for example, facilitate better decision-making in real-time [11]. Chatbots and interactive user interfaces are other examples of such methods. \n\t 2.2 Asynchronous  \n\t\t Asynchronous methods of sharing identity with AI systems involve tasks that can be implemented without the immediate involvement of the user under their permission. Examples of asynchronous methods of sharing identity with AI systems include the transfer of recorded identity-related information, background profiling, or medical records to manage and facilitate the sharing of identity-related data ensuring both privacy and security, whilst performing tasks that require coordination with the user, when they do not interact with the system [12]. \n According to ChatGPT [13] both distributed, decentralized and centralized algorithms can be either synchronous or asynchronous. Authentication and authorization practise, where AI systems provide support and grant access to specific data or services based on user permissions are also examples of both synchronous and asynchronous identity sharing methods. Biometric authentication, user profiling, encryption and anonymization \u2013 all play a role in sharing personal identity and allow data analysis while preserving privacy [14]. Communication, such as instant messaging and tailored news feed can also be considered in terms of both synchronous and asynchronous methods (Fig 1a). \n3.Application \nIn contemporary societies, an individual\u2019s identity is scattered across many domains, including programs, social media and increasingly also within AI systems. The idea of sharing identity can advance the AI ethics discussion, its governance and societal wellbeing. This question can be addressed by exploring the various applications of sharing identity with AI systems, which include (Fig. 1b): \n\u2022\n\u2022\n\u2022\nGlobal Identity or Global Environment Social Identity \nPersonal Identity or Individuality\n3.1Global Identity \nAI systems are also used provide a better understanding of what is necessary for a thriving global community.As a result of shared identity with AI systems, new social norms, might emerge which in turn will contribute to the development of global identity. Global identity must be based on the idea that developing advanced AI is a challenge for humanity as a whole to work collaboratively as the bounty of doing so is enormous. According to the collective identity view, each individual has I-mode and we-mode, and depending on the moral circle, one can attempt to encapsulate the AI systems into we-mode [15]. Global identity is particularly discussed within the environmental research given global climate change challenges and the necessity for humanity to react to it dynamically as a whole [16]. But, it becomes important within AI governance [17]. The goal within the global identity is either unequivocal (i.e., goal-directed) or hidden (e.g., backpropagation) to not interfere with one\u2019s observations and thus decision process. That is general, collective perception of self requires understanding self in we-mode, which is based on general or global information sharing. By global identity, the global environment is also assumed \u2013 the general reality that with AI system would encapsulate also virtual reality, constituting common environment. \n\t\t3.1.1 \tRecommender system \n\tRecommender systems are a subclass of information filtering systems which play a key role in decision-making processes, which contributes to identity development and sustainability. Indeed, recommender systems are in place of many domains in society's activity, including social media, the music and television industry, shopping, news, and the general search [18]. Many AI systems are employed for recommending products and services at the right time and place to accompany needs and preferences. Indeed, providing accurate recommendations is an important task to ease choice and improve general wellbeing. Decision scientists or behavioural architects worldwide work on appropriate recommendations in different domains, public policy being one [19]. One must be accurate in building a recommender system that would not interfere but guide and predict the goal of an individual, and even adjust the goal to a more \n\nAuthor name / Procedia Computer Science 00 (2023) 000\u2013000 \t5\noptimal one (i.e., set vs. growth mindset). The recommender system might also be used as a self-regulation activity, as it highlights specific patterns and biases of the user, which one can explicitly realise. Thus, the recommender system not only reflects user identity but must interact with the user\u2019s identity to provide appropriate service. \n\t\t3.1.2 \tCybersecurity \n\t Cybersecurity is one of the main concerns when it comes to sharing identity \u2013 data that represents an individual must be encrypted, preserved intact, and treated accordingly \u2013 as part of an individual. Data sharing in communication and how much we reveal ourselves directly, e.g., through messaging or indirectly through digital behavioural data is a perpetual way to understand self and receive feedback from others and recommender system. Reasonable care of organizations developing AI systems must be taken in safeguarding individuals when sharing identity from malicious intruders. Arguably social level identities, such as institutions and products that encompass an individual\u2019s experience in cyberspace protect user from mistreatment or errors [20]. Product settings should preserve user\u2019s control of identity through attention whilst using AI systems, to direct mental effort to important tasks [21], [22]. The policy for behavioural and cognitive cybersecurity, mental rules and social norms allow secure connections. For this training for initiating the process will be required. Deepfake detection methods can be used to address the challenge of identity theft and other data losses of individuals [23]. The detection process can be focused on inner consistency detection comparing inner identity with nearest neighbor search (1), using the inner identity of the suspect image, fin, to find its nearest neighbor in the reference set using the outer identity, represented by fout (2).  For this, retrieval of the corresponding outer identity fo\ud835\udc62\ud835\udc61\ud835\udc58\ud835\udc5c\ud835\udc62\ud835\udc61 in the reference set and computing the distance to the outer identity of the suspect image is made (3). \n \ud835\udc58\ud835\udc56\ud835\udc5b": null, " AI systems could be used to correct and treat malicious predispositions. Polarisation and misinformation, which is the result of biased communication can be persistent and dangerous [40]. Identity as a political association, individual demographics and other factors can be used to describe this bias [41]. Currently, there are several conventional ways to decrease bias: unbiasing individual preferences [42], [43], allowing specialization and expertise associated with diversity, for example, directing highly-emotive content in social media to a more balanced, rational view, and protect highly productive individuals\u2019 confidence and healthy herding, the features that can be used as part of successful global policy. \n4.Implications \n\t4.1 Work-related activities \n\tOne of the main implications of sharing identity with AI is within work. Some jobs will be inevitably lost due to automation, but using AI systems within science, medicine, management, community service and education domains are likely to withstand automation [44], [45]. Sharing identity is necessarily an individual\u2019s contribution to society as a whole with the format determined by the most appropriate contribution given the time, values, environment and individual preferences and predispositions (see Table 1). The social contribution, which is a paid activity, is versatile, meaning that many diverse individuals must \u201cagree\u201d to receive it, which is essential for humane AI systems. For example, online search is arguably one of the most commonly used tools in the world, among messaging, and navigation services. \nBuilding and prompting \u2018global identity\u2019 [46], [47]. As (the first) to realise such identity sharing for work, would be individuals who work directly with AI systems, i.e., AI researchers and developers. Indeed, organisations introduce \n\nAuthor name / Procedia Computer Science 00 (2023) 000\u2013000 \t7\na global policy for within corporate strategy promoting global identity, social responsibility cooperation and new economic competition across the teams via official statements and campaigns: \n\u2022\tEmbracing 'AI for society, a human-centred, ethical, and secure approach as opposed to 'AI for profit' and \t'AI for control' [48]": null, " \n\u2022\tProviding foresight for the Global Society [26]. \n\t\t4.2 Ethical Considerations \n\t The transformative potential of general-purpose AI, it can be argued that self-directed fully autonomous agents augment the human experience, that is interfere positively with people\u2019s processes, decreasing suffering and contributing to overall societal well-being and growth. The general purpose nature of AI systems makes it dual-use technology, which is defined as being both beneficial and harmful to humanity [49]. Dual-use also means having simultaneous applicability of AI systems to both commercial and defence domains. If one\u2019s identity is commercial rather than military, sharing it with AI would promote. The convergence of commercial and military applications is the premise by which both firms and the state have a stake in applying AI systems. This, in turn, brings the economic interest of commercial organisations into tension with the national organisations for mitigating security risks. \n\nFig. 2. Willingness to share personal data depends on self-concept (construal). Retrieved from [52]. \n Given the longtermism view and the complex nature of the shared environment, some forms of conflict and even conflict within AI systems just as within human experience are possible before the optimal behaviour within the environment is reached [50]. Such conflict in positive disposition might involve competition instead of war, assertiveness instead of aggression, tension instead of strain, and confronting instead of avoidance. Highlighting the best practices will be necessary for the purpose of increasing visibility and providing common ground for expertise, talent, comprehension, and trust [51]. As in the play, other types of conflict might take place that would contribute to learning. Continuously recording sensor and relevant internal status data, and monitoring might be necessary [52]. Willingness to disclose private information depends on individual differences, which is dependent on self-concept (construal). Individuals who have independent self-construal with a promotion focus are more likely to disclose personal information when presented with gain-framing information as compared to individuals with individuals with interdependent self-construal (Fig 2.) [53]. \n4.3 Medical use \n AI systems could share information with medical professionals for prophylactical reasons or to provide timely help, provide adaptive support that would regulate an individual\u2019s physiological or mental states and help to perform daily activities [7], [54]. For example, if a person is feeling stressed, the AI could appropriately filter and list in an appropriate manner the content of received information. Given the human tendency to alter mental states through activities and substances either to sustain or augment mental activities depending on the goal (or lack thereof": null, " for exploration), dependence is a well-known side-effect, thus medical experts must monitor and highlight predispositions when using AI systems. Medical use of shared identity with AI systems are also considered within neurodiversity domains. AI systems can be also used to direct predispositions of neurodiverse individuals to appropriately use their \n\n8 \tAlina Gutoreva / Procedia Computer Science 00 (2023) 000\u2013000\nskills and avoid imposing harm to improve one\u2019s wellbeing within the medical and social standards. An AI system is especially promising for people with disabilities or disorders by adapting to specific patient needs. For example, a recent study demonstrated a brain-computer interface that enabled a paralyzed woman to communicate through an avatar by reading brain activity into synthesized speech and facial expressions [55]. \n5.Conclusion \n One of the challenges of AI research and application is creating AI systems that align with user preferences, needs, and capabilities, ensuring that the technology is an effective and positively transformative extension of humanity. Within shared identity, individuality, social and global identities are realised and the versatile AI system level is advancing other levels. Synchronous, asynchronous and mixed methods exist to enable sharing identity. One of the key reasons for sharing identity with AI systems is understanding the self within the global environment and performing tasks moving closer to individual and social goals that would enable new social norms within AI Governance whilst developing individuality and expertise. With sharing identity comes the accompanying attributes including relatedness and solidarity within humanitarian goals and shared values with AI systems. \nAcknowledgements \nI would like to thank Pakizar Shamoi for her valuable feedback and advice in preparing this article. \nReferences\n[1] \tN. Bostrom, \u201cThe Vulnerable World Hypothesis,\u201d Glob. Policy, vol. 10, no. 4, pp. 455\u2013476, 2019, doi: \t10.1111/1758-5899.12718. \n[2] \tN. Bowerman, \u201cGood policy ideas that won\u2019t happen (yet),\u201d Effective Altruism Forum, 2014. [Online]. \tAvailable: https://www.fhi.ox.ac.uk/good-policy-ideas-that-wont-happen-yet/. [Accessed: 23-Aug-2023]. \n[3] \tH. Tajfel and J. Turner, \u201cAn Integrative Theory of Intergroup Conflict,\u201d in Key readings in social \tpsychology. Intergroup relations: Essential readings, A. Hogg and D. Abrams, Eds. New York, NY, US: \tPsychology Press, 1979, pp. 94\u2013109. \n[4] \tJ. C. Turner and K. J. Reynolds, \u201cSelf-categorization theory,\u201d in Handbook ofTheories of Social Psychology, \t2nd ed., P. A. M. Van Lange, A. W. Kruglanski, and E. T. Higgins, Eds. SAGE Publications, 2011, pp. 399\u2013\t417. \n[5] \tF. G. Neville, D. Novelli, J. Drury, and S. D. Reicher, \u201cShared social identity transforms social relations in \timaginary crowds,\u201d https://doi.org/10.1177/1368430220936759, vol. 25, no. 1, pp. 158\u2013173, Aug. 2020, \tdoi: 10.1177/1368430220936759. \n[6] \tM. Blanz, A. Mummendey, R. Mielke, and A. Klink, \u201cResponding to negative social identity: A taxonomy \tof identity management strategies,\u201d Eur. J. Soc. Psychol., vol. 28, no. 5, pp. 697\u2013729, 1998, doi: \t10.1002/(sici)1099-0992(199809/10)28:5<697::aid-ejsp889>3.0.co": null, "2-%23. \n[7] \tA. Hanif, X. Zhang, and S. Wood, \u201cA Survey on Explainable Artificial Intelligence Techniques and \tChallenges,\u201d Proc. - IEEE Int. Enterp. Distrib. Object Comput. Work. EDOCW, pp. 81\u201389, 2021, doi: \t10.1109/EDOCW52865.2021.00036. \n[8] \tUNICEF, \u201cSchoolgirls in Kazakhstan are Introducing Video Games into the Educational Processes,\u201d 2023. \t[Online]. Available: https://www.unicef.org/kazakhstan/en/press-releases/schoolgirls-kazakhstan-are-\tintroducing-video-games-educational-processes. [Accessed: 19-Aug-2023]. \n\n[9]\nAuthor name / Procedia Computer Science 00 (2023) 000\u2013000\n9\n\nR. Belk, \u201cExtended Self in a Digital World,\u201d J. Consum. Res. Inc. \u2022, vol. 40, 2013, doi: 10.1086/671052.\n\n[10]\nR. W. Belk, \u201cPossessions and the Extended Self,\u201d J. Consum. Res., vol. 15, no. 2, pp. 139\u2013168, Sep. 1988,\n\ndoi: 10.1086/209154. \n[11] \tF. Lieder, O. Chen, and T. L. Griffiths, \u201cDeveloping cognitive prostheses that leverage artificial intelligence \tand gamification to help people make better decisions,\u201d no. August, 2017, doi: \n\t10.1073/pnas.XXXXXXXXXX. \n[12] \tJ. Janeiro and G. Sjurseth, \u201cThe differences between synchronous web APIs and asynchronous stateful \tAPIs,\u201d Google Cloud Blog, 2021. [Online]. Available: https://cloud.google.com/blog/topics/developers-\tpractitioners/differences-between-synchronous-web-apis-and-asynchronous-stateful-apis/. [Accessed: 23-\tAug-2023]. \n[13] \tOpenAI, \u201cChatGPT.\u201d 2022. \n[14] \tC. Peukert, S. Bechtold, M. Batikas, and T. Kretschmer, \u201cEuropean Privacy Law and Global Markets for \tData,\u201d SSRN Electron. J., 2020, doi: 10.2139/ssrn.3560392. \nM. Gallotti and C. D. Frith, \u201cSocial cognition in the we-mode,\u201d Trends Cogn. Sci., vol. 17, no. 4, p. 160, [15] \n2013, doi: 10.1016/j.tics.2013.02.002. \n[16] \tI. Fritsche, M. Barth, P. Jugert, T. Masson, and G. Reese, \u201cA social identity model of pro-environmental \taction (SIMPEA),\u201d Psychol. Rev., vol. 125, no. 2, pp. 245\u2013269, 2018, doi: 10.1037/rev0000090. \n[17] \tA. Dafoe, \u201cAI Governance: A Research Agenda.\u201d 2018. \nF. Ricci, L. Rokach, and B. Shapira, \u201cRecommender Systems: Techniques, Applications, and Challenges,\u201d [18] \nRecomm. Syst. Handb. Third Ed., pp. 1\u201335, Jan. 2022, doi: 10.1007/978-1-0716-2197-4_1/COVER. \n[19] \tF. Naru and F. Cavassini, Behavioural Insights and Public Policy: Lessons from Around the World. Paris: \tOECD Publishing, 2017. \n[20] \tR. Wiblin and H. Lempel, \u201cWays people trying to do good accidentally make things worse, and how to \tavoid them,\u201d 80,000 Hours, 2018. [Online]. Available: https://80000hours.org/articles/accidental-harm/. \n[Accessed: 13-Feb-2019]. \n[21] \tU. Lyngs et al., \u201c\u2018I Just Want to Hack Myself to Not Get Distracted\u2019: Evaluating Design Interventions for \tSelf-Control on Facebook,\u201d in Conference on Human Factors in Computing Systems - Proceedings, 2020, \tdoi: 10.1145/3313831.3376672. \n[22] \tA. Shenhav et al., \u201cToward a Rational and Mechanistic Account of Mental Effort,\u201d \thttps://doi.org/10.1146/annurev-neuro-072116-031526, vol. 40, pp. 99\u2013124, Aug. 2017, doi: \t10.1146/ANNUREV-NEURO-072116-031526. \n[23] \tX. Dong et al., \u201cProtecting Celebrities from DeepFake with Identity Consistency Transformer,\u201d in \tProceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2022, \tvol. 2022-June, pp. 9458\u20139468, doi: 10.1109/CVPR52688.2022.00925. \n[24] \tY. J. Xiao, G. Coppin, and J. J. Van Bavel, \u201cPerceiving the World Through Group-Colored Glasses: A \tPerceptual Model of Intergroup Relations,\u201d Psychol. Inq., vol. 27, no. 4, pp. 255\u2013274, 2016, doi: \n\n10 \tAlina Gutoreva / Procedia Computer Science 00 (2023) 000\u2013000\n10.1080/1047840X.2016.1199221. \n[25] \tR. S. Sutton and A. G. Barto, Reinforcement learning: An introduction. 1998. \n[26] \tC. Cath, S. Wachter, B. Mittelstadt, M. Taddeo, and L. Floridi, \u201cArtificial Intelligence and the \u2018Good \tSociety\u2019: the US, EU, and UK approach,\u201d Sci. Eng. Ethics, vol. 24, no. 2, pp. 505\u2013528, Apr. 2018, doi: \t10.1007/S11948-017-9901-7. \n[27] \tC. Katzenbach and L. Ulbricht, \u201cAlgorithmic governance,\u201d Internet Policy Rev., vol. 8, no. 4, 2019, doi: \t10.14763/2019.4.1424. \n[28] \tN. Dhingra, J. Emmett, and B. Halpern, \u201cActivate purpose to create shared identity,\u201d McKinsey & Company, \t2020. [Online]. Available: https://www.mckinsey.com/capabilities/people-and-organizational-\n\tperformance/our-insights/the-organization-blog/activate-purpose-to-create-shared-identity. [Accessed: 22-\tAug-2023]. \n[29] \tC. D. Hardin and E. T. Higgins, \u201cShared reality: How social verification makes the subjective objective.,\u201d in \tHandbook of Motivation and Cognition: The Interpersonal Context, vol. 3, 1996, pp. 28\u201384. \n[30] \tE. T. Berkman, J. L. Livingston, and L. E. Kahn, \u201cFinding The \u2018Self\u2019 in Self-Regulation: The Identity-Value \tModel,\u201d Psychol. Inq., vol. 28, no. 2\u20133, pp. 77\u201398, 2017, doi: 10.1080/1047840X.2017.1323463. \n[31] \tD. Martin, J. Hutchison, G. Slessor, J. Urquhart, S. J. Cunningham, and K. Smith, \u201cThe Spontaneous \tFormation of Stereotypes via Cumulative Cultural Evolution,\u201d Psychol. Sci., vol. 25, no. 9, pp. 1777\u20131786, \t2014, doi: 10.1177/0956797614541129. \n[32] \tJ. D. Cohen, S. M. McClure, and A. J. Yu, \u201cShould I stay or should I go? How the human brain manages the \ttrade-off between exploitation and exploration,\u201d in Philosophical Transactions of the Royal Society B: \tBiological Sciences, 2007, vol. 362, no. 1481, pp. 933\u2013942, doi: 10.1098/rstb.2007.2098. \n[33] \tUniversity of Cambridge, \u201cApply Magic Sauce - Prediction API,\u201d University of Cambridge The \tPsychometrics Centre, 2020. [Online]. Available: https://applymagicsauce.com/demo. [Accessed: 22-Aug-\t2023]. \n[34] \tL. Mudrik et al., \u201cFree will without consciousness?,\u201d Trends in Cognitive Sciences, vol. 26, no. 7. Elsevier \tLtd, pp. 555\u2013566, 01-Jul-2022, doi: 10.1016/j.tics.2022.03.005. \n[35] \tT. Mirsch, C. Lehrer, and R. Jung, \u201cDigital Nudging: Altering User Behavior in Digital Environments,\u201d \tProc. 13th Int. Conf. Wirtschaftsinformatik, no. February, pp. 634\u2013648, 2017. \n[36] \tJ.-M. Benkert and N. Netzer, \u201cInformational Requirements of Nudging,\u201d SSRN Electron. J., no. 190, 2015, \tdoi: 10.2139/ssrn.2597631. \n[37] \tJ. B. Hirsh, S. K. Kang, and G. V. Bodenhausen, \u201cPersonalized Persuasion: Tailoring Persuasive Appeals to \tRecipients\u2019 Personality Traits,\u201d Psychol. Sci., vol. 23, no. 6, pp. 578\u2013581, 2012, doi: \n\t10.1177/0956797611436349. \n[38] \tT. Gr\u00fcne-Yanoff and S. Ove Hansson, Preference Change: Approaches from philosophy, economics and \tpsychology. 2009. \n[39] \tJ. Denrell and B. Kov\u00e1cs, \u201cThe effect of selection bias in studies of fads and fashions,\u201d PLoS One, vol. 10, \n\nAuthor name / Procedia Computer Science 00 (2023) 000\u2013000 \t11\nno. 4, pp. 1\u201319, 2015, doi: 10.1371/journal.pone.0123471. \n[40] \tJ. G. Montalvo and M. Reynal-Querol, \u201cEthnic Polarization, Potential Conflict, and Civil Wars,\u201d Am. Econ. \tRev., vol. 95, no. 3, pp. 796\u2013816, Jun. 2005, doi: 10.1257/0002828054201468. \n[41] \tO. Toubia, T. Evgeniou, E. Johnson, and P. Delqui\u00e9, \u201cDynamic experiments for estimating preferences: An \tadaptive method of eliciting time and risk parameters,\u201d Management Science, vol. 59, no. 3. pp. 613\u2013640, \t2013, doi: 10.1287/mnsc.1120.1570. \n[42] \tT. N. Wisdom, X. Song, and R. L. Goldstone, \u201cSocial Learning Strategies in Networked Groups,\u201d Cogn. \tSci., vol. 37, no. 8, pp. 1383\u20131425, Nov. 2013, doi: 10.1111/cogs.12052. \n[43] \tR. H. Thaler, \u201cNudge, not sludge,\u201d Science (80-. )., vol. 361, no. 6401, p. 431, 2018, doi: \t10.1126/science.aau9241. \n[44] \tC. B. Frey and M. A. Osborne, \u201cThe Future of Employment Relations,\u201d 2013. \n[45] \tJ. Brown et al., \u201cWorkforce of the future \u2013 The competing forces shaping 2030,\u201d 2017. \n[46] \tG. Grimalda, N. Buchan, and M. Brewer, \u201cSocial identity mediates the positive effect of globalization on \tindividual cooperation: Results from international experiments,\u201d PLoS One, vol. 13, no. 12, p. e0206819, \tDec. 2018, doi: 10.1371/journal.pone.0206819. \n[47] \tA. Rosenmann, G. Reese, and J. E. Cameron, \u201cSocial Identities in a Globalized World: Challenges and \tOpportunities for Collective Action,\u201d Perspect. Psychol. Sci., vol. 11, no. 2, pp. 202\u2013221, 2016, doi: \t10.1177/1745691615621272. \n[48] \tD. Partridge, \u201cArtificial Intelligence: A European Perspective,\u201d Publications Office of the European Union, \tLuxembourg, 2018. \n[49] \tA. Jade Leung, \u201cWho will govern artificial intelligence? Learning from the history of strategic politics in \temerging technologies Thesis submitted in partial fulfilment of the requirements for the degree of DPhil in \tInternational Relations in the Department of Politics a,\u201d 2019. \n[50] \tM. Brundage et al., \u201cThe Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation,\u201d \t2018, doi: 10.1002/adma.201405087. \n[51] \tG. Eden, M. Jirotka, and B. Stahl, \u201cResponsible research and innovation: Critical reflection into the potential \tsocial consequences of ICT,\u201d Proc. - Int. Conf. Res. Challenges Inf. Sci., no. May 2014, 2013, doi: \t10.1109/RCIS.2013.6577706. \n[52] \tA. F. T. Winfield and M. Jirotka, \u201cThe case for an ethical black box,\u201d Lect. Notes Comput. Sci. (including \tSubser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), vol. 10454 LNAI, pp. 262\u2013273, 2017, doi: \t10.1007/978-3-319-64107-2_21. \n[53] \tC. Zhang, C. Cui, and Q. Yao, \u201c\u2018I\u2019 Am Willing to Disclose, but \u2018We\u2019 are Unwilling: The Impact of Self-\tConstrual on Individuals\u2019 Willingness to Disclose,\u201d Psychol. Res. Behav. Manag., vol. 14, pp. 1929\u20131945, \t2021, doi: 10.2147/PRBM.S336223. \n[54] \tW. Samek, T. Wiegand, and K. R. M\u00fcller, \u201cExplainable artificial intelligence: Understanding, visualizing \tand interpreting deep learning models,\u201d arXiv. arXiv, 28-Aug-2017. \n\n12 \tAlina Gutoreva / Procedia Computer Science 00 (2023) 000\u2013000\n[55] \tS. L. Metzger et al., \u201cA high-performance neuroprosthesis for speech decoding and avatar control,\u201d Nature, \nvol. 1837, no. 1440, pp. 1\u201310, Aug. 2023, doi: 10.1038/s41586-023-06443-4.": null}